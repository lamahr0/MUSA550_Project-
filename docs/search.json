[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Introduction",
    "section": "",
    "text": "Urban parks play a significant role in shaping the social, environmental, and cultural landscape of a city. When thinking of urban parks, Central Park immediately comes to mind as an iconic attraction that serves as a destination for social activities, tourism, and as the green lungs of New York City.\nIn order to find out more about how urban parks shape the cities, this project aim to understand how urban parks impact the demographics property market and crime in the adjacent neighborhoods. Moreover, how urban parks can contribute to mitigating environmental challenges.\n\n:::"
  },
  {
    "objectID": "analysis/1-Demographics_Study.html",
    "href": "analysis/1-Demographics_Study.html",
    "title": "Urban Parks & Demographics",
    "section": "",
    "text": "Code\n#Data Collection\n#Methods to analyze\n#results \n\n\n\n\nCode\n#imports\nimport seaborn as sns \nimport pandas as pd\nimport numpy as np \nfrom matplotlib import pyplot as plt\nimport altair as alt\nimport geopandas as gpd\nimport json\nimport folium\nimport pygris\nimport cenpy\nimport re\nimport copy\nimport warnings\nimport holoviews as hv\nimport hvplot.pandas \nfrom holoviews import opts\nhv.extension('bokeh')\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom scipy.stats import pearsonr\n# Suppress all warnings\nwarnings.filterwarnings('ignore')\nfrom folium import Map, Marker\nfrom IPython.display import IFrame\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n#Check Parks\n#read shape file \nshape_file_loc =  'parks_map/geo_export_46a7de00-0067-42f5-a6bc-bec64e5a0f0b.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nparks_gpd =  get_gpd_df()\n\n#plot the map \npark_map = parks_gpd.explore(\n    tiles=\"Cartodb positron\",\n        style_kwds={\n        \"weight\": 2,\n        \"color\": \"green\",\n        \"fillOpacity\": 0.5,\n        }\n)\nfolium.TileLayer(opacity=0.20).add_to(park_map)\n#create api conncection\nny_state_code = \"36\"\nvariables = ['NAME', 'B16008_002E' #Native population\n             , 'B16008_019E' #Foreign-born population\n             , 'B25064_001E' , #median_rent\n             'B19013_001E'] #median_income\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\nNY_demo_data2021 = acs.query(\n    cols=variables,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": ny_state_code,  \"county\":  \"*\"},\n)\nacs2 = cenpy.remote.APIConnection(\"ACSDT5Y2010\")\nNY_demo_data2010 = acs2.query(\n    cols=variables,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": ny_state_code, \"county\": \"*\"},\n)\n\nNY_demo_data2010.dropna(inplace=True)\nNY_demo_data2021.dropna(inplace=True)\n\n#\"061\" Manhattan (New York County) 005 #Bronx 081 Queen  047  Brooklyn (Kings County) 085 Staten Island (Richmond County)\nny_city_counties = [\"061\" , \"005\" , \"081\", \"047\", \"085\"]\n\nNY_demo_data2010 = NY_demo_data2010[NY_demo_data2010['county'].isin(ny_city_counties)]\nNY_demo_data2021 = NY_demo_data2021[NY_demo_data2021['county'].isin(ny_city_counties)]\n\n\nfor variable in variables:\n    if variable != \"NAME\":\n        NY_demo_data2010[variable] = NY_demo_data2010[variable].astype(float)\n\nfor variable in variables:\n    if variable != \"NAME\":\n        NY_demo_data2021[variable] = NY_demo_data2021[variable].astype(float)\n        \nNY_demo_data2010['population2010'] = NY_demo_data2010['B16008_002E'] + NY_demo_data2010['B16008_019E']\nNY_demo_data2010 = NY_demo_data2010.rename(columns={'B19013_001E': 'median_income2010' ,'B25064_001E': 'median_rent2010'})\nNY_demo_data2010 = NY_demo_data2010[NY_demo_data2010['population2010']&gt;0]\nNY_demo_data2010 = NY_demo_data2010[NY_demo_data2010['median_income2010']&gt;=0]\n\nNY_demo_data2021['population2021'] = NY_demo_data2021['B16008_002E'] + NY_demo_data2021['B16008_019E']\nNY_demo_data2021 = NY_demo_data2021.rename(columns={'B19013_001E': 'median_income2021' ,'B25064_001E': 'median_rent2021'})\nNY_demo_data2021 = NY_demo_data2021[NY_demo_data2021['population2021']&gt;0]\nNY_demo_data2021 = NY_demo_data2021[NY_demo_data2021['median_income2021']&gt;=0]\n\n\npopulation_total_df = pd.merge(NY_demo_data2010, NY_demo_data2021 , on=['tract','county','NAME']) \n\npopulation_total_df['change_precent'] = ((population_total_df['population2021'] - population_total_df['population2010']) /(np.absolute(population_total_df['population2010'])))*100\n\nshape_file_loc =  'census_tract_shapefile/tl_2021_36_tract.shp'\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nnyc_gpd =  get_gpd_df()\n\nnyc_demo_merged = nyc_gpd.merge(\n    population_total_df,\n    left_on=[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\"],\n    right_on=[\"state_x\", \"county\", \"tract\"],)\n\nnyc_pct_change_mean = nyc_demo_merged['change_precent'].mean()\n\nnyc_demo_merged = nyc_demo_merged[['tract', 'geometry', 'population2010','population2021','change_precent'\n                                  ,'median_income2010' , 'median_income2021',\n                                  'median_rent2010','median_rent2021']]\nnyc_demo_merged = nyc_demo_merged[nyc_demo_merged['change_precent'] &lt; 300]\n\n\n\n\nCode\ndef style(feature):\n    return {\n        'fillColor': 'green',  \n        'color': 'black',      \n        'weight': 2,          \n        'fillOpacity': 0.6    \n    }\ndef mapping(df,col,parks_gpd=parks_gpd):\n\n    m = df.explore(column=col,cmap = 'Blues', \n                                tiles=\"CartoDB positron\", zoom_start=11)\n    folium.Marker(location=[40.747993, -74.004890], popup=\"The High Line\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.785091, -73.968285], popup=\"Central Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.665535, -73.969749], popup=\"Prospect Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.699215, -73.999039], popup=\"Brooklyn Bridge Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.739716, -73.840782], popup=\"Flushing Meadows Corona Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.703564, -74.016678], popup=\"Battery Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n\n    folium.GeoJson(\n        parks_gpd,\n        name='geojson_layer',\n        style_function=style\n    ).add_to(m)\n    \n    return m \n\n\n\nDo urban parks influence migration to nearby neighborhoods?\n\n\nCode\nm = mapping(nyc_demo_merged,\"change_precent\",parks_gpd=parks_gpd)\n# Save the map as HTML\nhtml_path = \"map1.html\"\nm.save(html_path)\n# Display the HTML file as an iframe\nIFrame(html_path, width=800, height=600)\n\n\n\n        \n        \n\n\n\n\nDid neighborhoods nearby urban parks experience a decrease in population between Census 2010 and Census 2020?\n\n\nCode\nnyc_demo_merged_sub_loss = nyc_demo_merged[nyc_demo_merged['change_precent'] &lt; 0]\nm2 = mapping(nyc_demo_merged_sub_loss,\"change_precent\",parks_gpd=parks_gpd)\n# Save the map as HTML\nhtml_path = \"map2.html\"\nm2.save(html_path)\n# Display the HTML file as an iframe\nIFrame(html_path, width=800, height=600)\n#decreased \n\n\n\n        \n        \n\n\n\n\nDoes the variation in rental prices contribute to the population decline in areas experiencing a decrease?\n\n\nCode\ndef compare(df, tracts , park_name):\n    df.tract = df.tract.astype(str)\n    df = df[df.tract.isin(tracts)]\n    df = df[['median_income2010', 'median_income2021','median_rent2010' , 'median_rent2021']]\n    mean = df.mean(axis=0).reset_index()\n    mean = mean.rename(columns={\n    'index': 'Variable',\n    0: 'Values'})\n    rent = mean[mean['Variable'].str.contains('rent')]\n    income = mean[mean['Variable'].str.contains('income')]\n\n    rent['Year'] = rent['Variable'].astype(str).str[-4:]\n    income['Year'] = income['Variable'].astype(str).str[-4:]\n    \n    fig, axes = plt.subplots(1, 2, figsize=(8, 4), gridspec_kw={'width_ratios': [1, 1]})\n    sns.barplot(x='Year', y='Values', data=rent, palette='pastel', ax=axes[0])\n    axes[0].set_xlabel('year')\n    axes[0].set_ylabel('Median Rent')\n    axes[0].set_title('Median Rent In ' + park_name + ' Area' , fontsize=10)\n    sns.barplot(x='Year', y='Values', data=income, palette='pastel', ax=axes[1])\n    axes[1].set_xlabel('year')\n    axes[1].set_ylabel('Median Income')\n    axes[1].set_title('Median Income  In ' + park_name + ' Area' , fontsize=10)\n    plt.tight_layout()\n    # Show the plots\n    plt.show()\n\n\n\n\nCode\ncentral = ['013000' , '012000' , '015001' , '015002']\ncompare(nyc_demo_merged_sub_loss, central , 'Central Park')\n\n\n\n\n\n\n\nCode\nbrooklyn = [ '000301' ]\ncompare(nyc_demo_merged_sub_loss, brooklyn , 'Brooklyn Bridge Park')\n\n\n\n\n\n\n\nCode\nwsqaure = [ '006500' ]\ncompare(nyc_demo_merged_sub_loss, wsqaure , 'Washington SquareÂ Park')\n\n\n\n\n\n\n\nCode\nwsqaure = [ '003900' ]\ncompare(nyc_demo_merged_sub_loss, wsqaure , 'Silver Lake Park')\n\n\n\n\n\n\n\nIs there a correlation between median income and the accessibility of parks?\n\n\nCode\nwith open('indicators_data/2388.json', 'r') as file:\n    park_walking_data = json.load(file)\n    \npark_walking_data = pd.DataFrame(park_walking_data)\npark_walking_data = park_walking_data[park_walking_data.GeoType==\"UHF42\"]\n\nshape_file_loc = 'UHF 42/UHF_42_DOHMH.shp'\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nuhf_gpd =  get_gpd_df()\nuhf_gpd.to_crs(epsg = \"4326\", inplace = True)\n\nmerged_ny_walking = uhf_gpd.merge(\n    park_walking_data,\n    left_on=[\"UHF\"],\n    right_on=[\"GeoID\"])\n\njoined_data = gpd.sjoin(nyc_demo_merged, merged_ny_walking, how='left', op='within')\njoined_data.dropna(inplace=True)\n\nnumerical_correlation, _ = pearsonr(joined_data['Value'], joined_data['median_income2010'])\nprint(f\"Pearson's correlation coefficient: {numerical_correlation}\")\n\nnumerical_correlation, _ = pearsonr(joined_data['Value'], joined_data['median_income2021'])\nprint(f\"Pearson's correlation coefficient: {numerical_correlation}\")\n\nm = mapping(joined_data,\"Value\",parks_gpd=parks_gpd)\n# Save the map as HTML\nhtml_path = \"map1.html\"\nm.save(html_path)\n# Display the HTML file as an iframe\nIFrame(html_path, width=800, height=600)\n\n\nPearson's correlation coefficient: -0.263688800485939\nPearson's correlation coefficient: -0.12378378631103196\n\n\n\n        \n        \n\n\n\n\nIs there a correlation between the presence of families in nearby neighbourhoods and the availability of Children Playgrounds?\n\n\nCode\nshape_file_loc = 'CPA/geo_export_f2e1ecf0-ad20-4676-8b9d-ee96dfeef1bd.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nCPA_gpd =  get_gpd_df()\n\n\nshape_file_loc = 'Athletic_Facilities/geo_export_35c572bd-a799-446c-890f-c78e4d293ea0.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nAF_gpd =  get_gpd_df()\n\n#source https://docs.google.com/spreadsheets/d/1iIhwuLBlIus2n1EQ2a329jX4oJciXt9dEaxOFPpHfE8/edit?usp=sharing\nsport_map = {\n    'BKB': 'Basketball',\n    'BSB': 'Baseball',\n    'CRK': 'Cricket',\n    'FFB': 'Flag Football',\n    'FRS': 'Frisbee',\n    'FTB': 'Football',\n    'HDB': 'Handball',\n    'HKY': 'Hockey',\n    'KBL': 'Kickball',\n    'LCS': 'Lacrosse',\n    'MPPA': 'Multi Purpose Play Area',\n    'NTB': 'Netball',\n    'RBY': 'Rugby',\n    'SCR': 'Soccer',\n    'SFB': 'Softball',\n    'TNS': 'Tennis',\n    'TRK': 'Track',\n    'VLB': 'Volleyball',\n    'WFB': 'Wheelchair Football'\n}\n\nAF_gpd['primary_sp'] = AF_gpd['primary_sp'].replace(sport_map)\nAF_count = AF_gpd.groupby('primary_sp').size().reset_index(name='Count')\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='primary_sp', y='Count', data=AF_count, palette='Set2')\nax.set_title('Sports Facilities in NYC Parks' , fontsize=16)\nax.set_xlabel('Sport')\nax.set_ylabel('Freq')\nplt.xticks(rotation=45, ha='right');\n\n\n\n\n\n\n\nCode\nimport folium\nfrom folium.plugins import MarkerCluster\n\nm = folium.Map(location=[40.747993, -74.004890] , tiles=\"Cartodb positron\", zoom_start=10)\nplaygrounds_cluster = MarkerCluster(name='Children Play Area').add_to(m)\nfor idx, row in CPA_gpd.iterrows():\n    folium.Marker(location=[row['geometry'].centroid.y, row['geometry'].centroid.x], popup=row['name']).add_to(playgrounds_cluster)\n\nathletic_cluster = MarkerCluster(name='Athletic Facilities').add_to(m)\nfor idx, row in AF_gpd.iterrows():\n    folium.Marker(location=[row['geometry'].centroid.y, row['geometry'].centroid.x] ,popup=row['primary_sp']).add_to(athletic_cluster)\n\nfolium.LayerControl().add_to(m)\n\nhtml_path = \"FA_CPA_Map.html\"\nm.save(html_path)\n# Display the HTML file as an iframe\nIFrame(html_path, width=800, height=600)\n\n\n\n\n        \n        \n\n\n\n\nCode\nvars_fam = ['NAME', 'B11012_003E', 'B11012_006E', 'B11012_010E','B11012_015E']\n\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\nNY_fam_data2021 = acs.query(\n    cols=vars_fam,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": ny_state_code,  \"county\":  \"*\"},\n)\nNY_fam_data2021 = NY_fam_data2021[NY_fam_data2021['county'].isin(ny_city_counties)]\nfor variable in vars_fam:\n    if variable != \"NAME\":\n        NY_fam_data2021[variable] = NY_fam_data2021[variable].astype(float)\n        \nNY_fam_data2021['Total_Families'] = NY_fam_data2021[['B11012_003E', 'B11012_006E', 'B11012_010E','B11012_015E']].sum(axis=1)\n\nnyc_fam_merged = nyc_gpd.merge(\n    NY_fam_data2021,\n    left_on=[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\"],\n    right_on=[\"state\", \"county\", \"tract\"],)\n\n\n\n\nCode\njoined_data2 = gpd.sjoin(CPA_gpd, nyc_fam_merged, how=\"inner\", op=\"within\")\njoined_data2.drop_duplicates(subset=['location','county'], inplace=True)\n\nplaygrounds_per_tract = joined_data2.groupby(['tract', 'county']).size().reset_index(name='CPA_Count')\nCPA_fam_count = nyc_fam_merged.merge(playgrounds_per_tract, how='left', left_on=['tract','county'], right_on=['tract','county'])\nCPA_fam_count.dropna(inplace=True)\nCPA_fam_count = CPA_fam_count[CPA_fam_count.Total_Families&gt;0]\n\ncorrelation_coefficient, p_value = pearsonr(CPA_fam_count['CPA_Count'], CPA_fam_count['Total_Families'])\n\ncorrelation_coefficient\n\n\n0.07816702466699046\n\n\n\n\nCode\n%matplotlib inline\nplt.figure(figsize=(7, 3))\nsns.scatterplot(x='Total_Families', y='CPA_Count', data=CPA_fam_count)\nplt.title('Number of Playgrounds vs Total Families')\nplt.xlabel('families count')\nplt.ylabel('Number of children Play Area')\nplt.show()\n\n\n\n\n\n\n\nIs there a corrleation between regular exercise and the avaliability atheltic facilities at parks ?\n\n\nCode\nwith open('indicators_data/2060.json', 'r') as file:\n    physical_activity_data = json.load(file)\n\nphysical_activity_data = pd.DataFrame(physical_activity_data)\nphysical_activity_data = physical_activity_data[physical_activity_data.GeoType==\"UHF42\"]\nphysical_activity_data.GeoID = physical_activity_data.GeoID.astype(float)\n\nphysical_activity_data = physical_activity_data[physical_activity_data.Time=='2019']\nmerged_ny_physical = uhf_gpd.merge(\n    physical_activity_data,\n    left_on=[\"UHF\"],\n    right_on=[\"GeoID\"])\n\njoined_gdf = gpd.sjoin(AF_gpd, merged_ny_physical, how='inner', op='intersects')\n\ntract_aggregated = joined_gdf.groupby(['GeoID','borough' ])['system'].count().reset_index()\n\nmerged_data = pd.merge(tract_aggregated, physical_activity_data, on=['GeoID'])\n\ncorrelation_coefficient, p_value = pearsonr(merged_data['system'], merged_data['Value'])\ncorrelation_coefficient\n\n\n-0.2820924647154564\n\n\n\n\nIs there a corrleation between exercise and accessibility of parks?\n\n\nCode\n#Physical Activity \nwith open('indicators_data/2060.json', 'r') as file:\n    physical_activity_data = json.load(file)\n    \nwith open('indicators_data/2388.json', 'r') as file:\n    park_walking_data = json.load(file)\n    \n#read shape file for UHF 42\nshape_file_loc = 'UHF 42/UHF_42_DOHMH.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nuhf_gpd =  get_gpd_df()\nuhf_gpd.to_crs(epsg = \"4326\", inplace = True)\n\n\nphysical_activity_data = pd.DataFrame(physical_activity_data)\nphysical_activity_data = physical_activity_data[physical_activity_data.GeoType==\"UHF42\"]\nphysical_activity_data.GeoID = physical_activity_data.GeoID.astype(float)\nmerged_ny_physical = uhf_gpd.merge(\n    physical_activity_data,\n    left_on=[\"UHF\"],\n    right_on=[\"GeoID\"])\n\nplot = merged_ny_physical.hvplot(\n    c=\"Value\",\n    groupby=\"Time\",\n    frame_width=600,\n    frame_height=600,\n    geo=True,\n    dynamic=False,\n    cmap=\"Greens\",\n    hover_cols=[\"GEOID\"]\n)\nplot.opts(title='Recent Exercise in NY by Neighbourhood')\n\n\n\n\n\n\n  \n\n\n\n\n\n\nCode\n#ref:\n#https://a816-dohbesp.nyc.gov/IndicatorPublic/data-explorer/physical-activity/?id=2060\n\npark_walking_data = pd.DataFrame(park_walking_data)\npark_walking_data = park_walking_data[park_walking_data.GeoType==\"UHF42\"]\n\nphysical_activity_data = physical_activity_data[physical_activity_data.Time=='2017']\n\nmerged_ny_walking = uhf_gpd.merge(\n    park_walking_data,\n    left_on=[\"UHF\"],\n    right_on=[\"GeoID\"])\n\nplot = merged_ny_walking.hvplot(\n    c=\"Value\",\n    groupby=\"Time\",\n    frame_width=600,\n    frame_height=600,\n    geo=True,\n    dynamic=False,\n    cmap=\"Greens\",\n    hover_cols=[\"GEOID\"]\n)\nplot.opts(title='Walking Distance to a Park in NY by Neighbourhood in 2017')\n\n\n\n\n\n\n  \n\n\n\n\n\n\nCode\nmerged_walking_corr = physical_activity_data.merge(\n    park_walking_data, on=['GeoID', 'Time'])\ncorrelation_coefficient, p_value = pearsonr(merged_walking_corr.Value_x,merged_walking_corr.Value_y)\ncorrelation_coefficient\n\n\n0.28957159180561953\n\n\n\n\nCode\nplt.figure(figsize=(7, 3))\nsns.scatterplot(x='Value_x', y='Value_y', data=merged_walking_corr)\nplt.title('Park Accessibility Vs Exercise rate')\nplt.xlabel('% Of recent exercise per area responses')\nplt.ylabel('% of Accessabile Parks per responses')\nplt.show()"
  },
  {
    "objectID": "analysis/Estate_env.html",
    "href": "analysis/Estate_env.html",
    "title": "Real Estate & Environment",
    "section": "",
    "text": "Are property values higher in neighborhoods with proximity to parks?\n\n\nCode\nimport altair as alt\nimport geopandas as gpd\nimport json\nimport folium\nimport pygris\nimport numpy as np\nimport cenpy\nimport re\nimport copy\nimport warnings\nimport holoviews as hv\nimport hvplot.pandas \nfrom holoviews import opts\nhv.extension('bokeh')\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom scipy.stats import pearsonr\nimport warnings\nfrom folium import Map, Marker\nfrom IPython.display import IFrame\nimport cenpy\nimport numpy as np\nimport seaborn as sns \nimport pandas as pd\nimport pygris\nimport geopandas as gpd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.options.mode.chained_assignment = None\npd.set_option('mode.chained_assignment', None)\nimport warnings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Suppress all warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('mode.chained_assignment', None)\n#ref https://www.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf\nsales = pd.read_csv(\"nyc-property-sales.csv\" )\nsales.drop_duplicates(inplace=True)\nsales.dropna(inplace=True)\n\nsales[' ZIP CODE'] = pd.to_numeric(sales[' ZIP CODE'], errors='coerce')\nsales = sales.dropna(subset=[' ZIP CODE'])\n\nsales['SALE DATE'] = pd.to_datetime(sales['SALE DATE'])\nsales['year'] = sales['SALE DATE'].dt.year\nsales.replace(' -  ', 0,  inplace=True)\nsales.replace(np.nan,0, inplace=True)\nsales['SALE PRICE'] = sales['SALE PRICE'].astype(float)\nsales['SALE_PRICE_M'] = sales['SALE PRICE'].astype(np.float64) / 1000000\n\ndef calculate_mean_sales(df,zip_codes):\n    df = df[df[' ZIP CODE'].isin(zip_codes)]\n    mean_sales_by_year = df.groupby('year')['SALE_PRICE_M'].mean().reset_index()\n    return mean_sales_by_year\n\nhigh_line = [10001, 10011, 10018]\nhl = calculate_mean_sales(sales,high_line)\nhl['park'] = 'High Line'\n#central sales \nCentral =  [10019, 10023, 10024, 10025]\ncn = calculate_mean_sales(sales,Central)\ncn['park'] = 'Central Park'\n#Prospect sales \nProspect = [11215, 11217, 11218]\npr = calculate_mean_sales(sales,Prospect)\npr['park'] = 'Prospect Park'\n#Brooklyn Bridge sales \nBrooklynBridge =  [11201, 11205, 11217]\nBrooklyn = calculate_mean_sales(sales,BrooklynBridge)\nBrooklyn['park'] = 'Brooklyn Park'\n#Flushing sales \nFlushing_Park =[11368, 11369, 11373]\nfp = calculate_mean_sales(sales,Flushing_Park)\nfp['park'] = 'Flushing Park'\n#Battery sales \nBattery= [10004, 10005, 10006]\nbt = calculate_mean_sales(sales,Battery)\nbt['park'] = 'Battery Park'\nbt = calculate_mean_sales(sales,Battery)\nbt['park'] = 'Battery Park'\n\noverall = sales.groupby('year')['SALE_PRICE_M'].mean().reset_index()\noverall['park'] = 'NYC'\n\n\nmean_sales = pd.concat([hl, cn, pr ,Brooklyn , fp , bt , overall], ignore_index=True)\nplt.figure(figsize=(10, 6))\nsns.lineplot(x='year', y='SALE_PRICE_M', hue='park', data=mean_sales, marker='o' ,palette='deep' )\nplt.xlabel('Date')\nplt.ylabel('Sales ( Millions $)')\nplt.title('Mean Prices for Property Sales in Areas Around Parks')\nplt.show()\n\n\n\n\n\n\n\nWhat are the predominant land use around urban parks in NYC?\n\n\nCode\nsales['Class'] = np.where(sales['BUILDING CLASS AT PRESENT'].str.contains('^[ABCDSL]|^R[1-4]', case=False ,regex=True) , 'Residential' , 'Else')\nsales['Class'] = np.where(sales['BUILDING CLASS AT PRESENT'].str.contains('^V', case=False ,regex=True) , 'Vacant' , sales['Class'])\nsales['Class'] = np.where(sales['BUILDING CLASS AT PRESENT'].str.contains('^[KORB]', case=False ,regex=True) , 'Commercial' , sales['Class'])\nsales['Class'] = np.where(sales['BUILDING CLASS AT PRESENT'].str.contains('^[H]', case=False ,regex=True) , 'Hotel' , sales['Class'])\nparks_codes = [10001, 10011, 10018, 10019, 10023, 10024, 10025 , 11215, 11217, 11218 , 11201, 11205, 11217,\n              11201, 11205, 11217, 11368, 11369, 11373 , 10004, 10005, 10006 ]\n\nnyc_use = sales['Class'].value_counts().reset_index()\nhigh_line = [10001, 10011, 10018]\nhl_sales =  sales[sales[' ZIP CODE'].isin(high_line)]\nhl_class = hl_sales['Class'].value_counts().reset_index()\n#central sales \nCentral =  [10019, 10023, 10024, 10025]\nCentral_sales =  sales[sales[' ZIP CODE'].isin(Central)]\nCentral_class = Central_sales['Class'].value_counts().reset_index()\n#Prospect sales \nProspect = [11215, 11217, 11218]\nProspect_sales =  sales[sales[' ZIP CODE'].isin(Prospect)]\nProspect_class = Prospect_sales['Class'].value_counts().reset_index()\n#Brooklyn Bridge sales \nBrooklynBridge =  [11201, 11205, 11217]\nBrooklyn_sales =  sales[sales[' ZIP CODE'].isin(BrooklynBridge)]\nBrooklyn_class = Brooklyn_sales['Class'].value_counts().reset_index()\n#Flushing sales \nFlushing_Park =[11368, 11369, 11373]\nFlushing_sales =  sales[sales[' ZIP CODE'].isin(Flushing_Park)]\nFlushing_class = Flushing_sales['Class'].value_counts().reset_index()\n#Battery sales \nBattery= [10004, 10005, 10006]\nBattery_sales =  sales[sales[' ZIP CODE'].isin(Battery)]\nBattery_class = Battery_sales['Class'].value_counts().reset_index()\n\n\npark_dfs = [hl_class, Central_class , Prospect_class , Brooklyn_class , Flushing_class , Battery_class , nyc_use]  # Add all park DataFrames to this list\nparks_names = ['High line', 'Central park' ,'Prospect park' , 'Brooklyn park', 'Flushing park',  'Battery_park' , 'NYC']\n\n\nfig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))\nfig.suptitle('Building Types Counts in Each Park', y=1.02 ,fontsize=16)\norder = ['Residential', 'Commercial', 'Else', 'Vacant', 'Hotel']\naxes = axes.flatten()\n\n\nfor i, (park_name, park_df) in enumerate(zip(parks_names, park_dfs)):\n    sns.barplot(x='Class', y='count', data=park_df, ax=axes[i] , palette='Greens_r' , order=order)\n    axes[i].set_title(park_name, fontsize=16)\n    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n\n\nplt.tight_layout()\nplt.xticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\nHow does the land use composition of an area (residential, commercial, industrial) affect the temperature reduction impact of nearby parks?\n\n\n& Do the presence of parks affect the surface temperature?\n\n\nCode\nimport geopandas as gpd\n\n# Specify the path to your GeoJSON file\ngeojson_file_path = 'https://services5.arcgis.com/GfwWNkhOj9bNBqoJ/arcgis/rest/services/NYC_Neighborhood_Tabulation_Areas_2010/FeatureServer/0/query?where=1=1&outFields=*&outSR=4326&f=pgeojson'\n\n# Read the GeoJSON file\ngdf = gpd.read_file(geojson_file_path)\n\n\nwith open('indicators_data/2141.json', 'r') as file:\n    temp_data = json.load(file)\n\ntemp_data = pd.DataFrame(temp_data)\n\n#read shape file for UHF 42\nshape_file_loc = 'UHF 42/UHF_42_DOHMH.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nuhf_gpd =  get_gpd_df()\nuhf_gpd.to_crs(epsg = \"4326\", inplace = True)\n\n\ntemp_data = temp_data[temp_data.GeoType==\"UHF42\"]\ntemp_data.GeoID = temp_data.GeoID.astype(float)\nmerged_ny_temp_data = uhf_gpd.merge(\n    temp_data,\n    left_on=[\"UHF\"],\n    right_on=[\"GeoID\"])\n\nshape_file_loc =  'parks_map/geo_export_46a7de00-0067-42f5-a6bc-bec64e5a0f0b.shp'\n\n#convert it into geopanda dataframe \ndef get_gpd_df(use_shape_file=True):\n    if use_shape_file:\n        gdf = gpd.read_file(shape_file_loc)\n    return gdf\nparks_gpd =  get_gpd_df()\n\ndef style(feature):\n    return {\n        'fillColor': 'green',  \n        'color': 'black',      \n        'weight': 2,          \n        'fillOpacity': 0.6    \n    }\ndef mapping(df,col, parks_gpd=parks_gpd):\n\n    m = df.explore(column=col,cmap = 'Blues', \n                                tiles=\"CartoDB positron\", zoom_start=11)\n    folium.Marker(location=[40.747993, -74.004890], popup=\"The High Line\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.785091, -73.968285], popup=\"Central Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.665535, -73.969749], popup=\"Prospect Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.699215, -73.999039], popup=\"Brooklyn Bridge Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.739716, -73.840782], popup=\"Flushing Meadows Corona Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.Marker(location=[40.703564, -74.016678], popup=\"Battery Park\" , icon=folium.Icon(icon='tree' ,color='red')).add_to(m)\n    folium.GeoJson(\n    parks_gpd,\n    name='geojson_layer',\n    style_function=style\n    ).add_to(m)\n    return m \n\n\n\nm = mapping(merged_ny_temp_data,\"Value\")\n# Save the map as HTML\nhtml_path = \"map1.html\"\nm.save(html_path)\n# Display the HTML file as an iframe\nIFrame(html_path, width=800, height=600)\n\n\n\n        \n        \n\n\n\n\nIs there a corrleation between vegetative cover and surface temperature\n\n\nCode\n#veg= 2143\n\nimport pandas as pd\nimport json\nwith open('indicators_data/2143.json', 'r') as file:\n    v_data = json.load(file)\n\nv_data = pd.DataFrame(v_data)\nv_data = v_data[v_data['GeoType']=='UHF42']\n\nmerged_ny = temp_data.merge(\n    v_data,\n    left_on=[\"GeoID\"],\n    right_on=[\"GeoID\"])\n\ntemp = temp_data[temp_data['GeoType']=='UHF42']\n\nfrom scipy.stats import pearsonr\nnumerical_correlation, _ = pearsonr(merged_ny['Value_x'], merged_ny['Value_y'])\nprint(f\"Pearson's correlation coefficient: {numerical_correlation}\")\n\n#| echo: true \n#| code-fold: true\n%matplotlib inline\nplt.figure(figsize=(7, 3))\nsns.scatterplot(x='Value_y', y='Value_x', data=merged_ny)\nplt.title('vegetative cover Vs temperature')\nplt.xlabel('vegetation level')\nplt.ylabel('temperature')\nplt.show()\n\n\nPearson's correlation coefficient: -0.4628346272603856"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis"
  }
]